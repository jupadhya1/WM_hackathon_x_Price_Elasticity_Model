{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e2445788",
   "metadata": {},
   "source": [
    "**Note**: Before running this notebook, make sure to run the `1. Baseline calculation.ipynb` notebook and output the updated `pkl` files in the `./interim_output/1. Baseline calculation/` needed to run this notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "572cab20",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2849396",
   "metadata": {},
   "source": [
    "# <span style=\"color:#c6aa3d\">0. Importing libraries and defining paths</span><a class=\"anchor\" id=\"0-bullet\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72a8625c",
   "metadata": {},
   "source": [
    "### 0.1 Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8c66b3cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing python libraries\n",
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6ed3193c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting the default max row and column display\n",
    "pd.set_option(\"display.max_columns\", 500)\n",
    "pd.set_option(\"display.max_rows\", 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "08a51870",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Asus\\anaconda3\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:7: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  from pandas import (to_datetime, Int64Index, DatetimeIndex, Period,\n",
      "C:\\Users\\Asus\\anaconda3\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:7: FutureWarning: pandas.Float64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  from pandas import (to_datetime, Int64Index, DatetimeIndex, Period,\n"
     ]
    }
   ],
   "source": [
    "# Path to src folder\n",
    "SCRIPT_DIR = os.path.dirname(os.path.realpath(os.path.join(os.getcwd())))\n",
    "sys.path.append(SCRIPT_DIR)\n",
    "\n",
    "# Import own scripts\n",
    "import src.config as config\n",
    "import src.custom_funcs as custom_funcs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cc23cb5",
   "metadata": {},
   "source": [
    "### 0.2 Defining paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d7000e13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input/Output Folder\n",
    "notebook_output_path = \"./output/2. RMI and Optimal Depth/\"\n",
    "baseline_interim_out_path = \"./interim_output/1. Baseline calculation/\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fa44af8",
   "metadata": {},
   "source": [
    "# <span style=\"color:#c6aa3d\">1. Reading interim files</span><a class=\"anchor\" id=\"1-bullet\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00af25f0",
   "metadata": {},
   "source": [
    "### 1.1 Importing model results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c55b01ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_df_final = pd.read_pickle(baseline_interim_out_path + \"param_df_final.pkl\")\n",
    "pred_df_final = pd.read_pickle(baseline_interim_out_path + \"pred_df_final.pkl\")\n",
    "base_df_final = pd.read_pickle(baseline_interim_out_path + \"base_df_final.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31c0c398",
   "metadata": {},
   "source": [
    "### 1.2 Importing model features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "50950200",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read model features data\n",
    "df_feat_ohe = pd.read_pickle(baseline_interim_out_path + \"features_df.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ebb6c43",
   "metadata": {},
   "source": [
    "### 1.3 Importing SKU attributes mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "48546a5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read sku attributes mapping\n",
    "df_sku_new_mapping = pd.read_pickle(baseline_interim_out_path + \"sku_new_mapping.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b55525e",
   "metadata": {},
   "source": [
    "### 1.4 Importing aggregated raw datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "edc22e97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read aggregated raw modeling data\n",
    "model_df_grouped = pd.read_pickle(baseline_interim_out_path + \"model_df_grouped.pkl\")\n",
    "model_df_grouped = model_df_grouped.rename(columns={'week_start_date':'ds'})\n",
    "\n",
    "# Read aggregated full raw data\n",
    "full_df_grouped = pd.read_pickle(baseline_interim_out_path + \"full_df_grouped.pkl\")\n",
    "full_df_grouped = full_df_grouped.rename(columns={'week_start_date':'ds'})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "357cb2c5",
   "metadata": {},
   "source": [
    "# <span style=\"color:#c6aa3d\">2. Data processing</span><a class=\"anchor\" id=\"2-bullet\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b51c117",
   "metadata": {},
   "source": [
    "### 2.1 Merging SKU-week prediction and baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "41a3b331",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merging pred and base df\n",
    "pred_and_baseline = pred_df_final.copy()\n",
    "pred_and_baseline = pd.merge(pred_and_baseline, \n",
    "                             base_df_final[[\"rfg\", \"ds\", \"yhat\"]], \n",
    "                             how=\"inner\", \n",
    "                             on=[\"rfg\", \"ds\"])\n",
    "pred_and_baseline = pred_and_baseline.rename(columns={\"yhat_x\": \"yhat\",\n",
    "                                                      \"yhat_y\": \"yhat_baseline\"})\n",
    "\n",
    "pred_and_baseline = pd.merge(pred_and_baseline,\n",
    "                             df_feat_ohe[[\"rfg\", \"ds\", \"price\", \"base_price\"]],\n",
    "                             how=\"inner\",\n",
    "                             on=[\"rfg\", \"ds\"])\n",
    "\n",
    "assert pred_df_final.shape[0]==pred_and_baseline.shape[0], \"[ERROR] Rows count has changed\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc2c6b50",
   "metadata": {},
   "source": [
    "### 2.2 Checking grouping variable for analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5b319f9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if group_OD_depth has one of the 2 values\n",
    "# Banner should be one of the grouping variables\n",
    "group_OD_depth = config.group_OD_depth\n",
    "\n",
    "assert group_OD_depth == ['banner','BRAND_GROUP','CREDIT_CONSIGN'] or \\\n",
    "        group_OD_depth == ['banner','BRAND_GROUP','SUBCLASS','CREDIT_CONSIGN'], \\\n",
    "        \"group_OD_depth variable should be either ['banner','BRAND_GROUP','CREDIT_CONSIGN'] or ['banner','BRAND_GROUP','SUBCLASS','CREDIT_CONSIGN']\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4864885d",
   "metadata": {},
   "source": [
    "### 2.3 Filtering features data for final modeled SKUs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d85d9916",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_OD = df_feat_ohe.copy()\n",
    "\n",
    "# Include only final shortlisted SKUs\n",
    "df_OD = df_OD[df_OD['rfg'].isin(param_df_final['rfg'])]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49dfdaf8",
   "metadata": {},
   "source": [
    "### 2.4 Merging other information and calculating metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5e6496d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "original_df_OD_count = df_OD.shape[0]\n",
    "\n",
    "# Getting supplier funding metrics and excluding vat metrics\n",
    "df_OD = df_OD.merge(model_df_grouped, on =['banner','sku_id_upd','ds'], how='inner')\n",
    "\n",
    "# Getting sku attributes\n",
    "df_OD = df_OD.merge(df_sku_new_mapping, on='sku_id_upd', how='inner')\n",
    "\n",
    "# Getting baselines for each SKU-week\n",
    "df_OD = df_OD.merge(pred_and_baseline[['rfg','ds','yhat_baseline']], on=['rfg','ds'], how='inner')\n",
    "\n",
    "df_OD['TOTAL_PRODUCT_COST'] = df_OD['COST_OF_GOODS_SOLD'] \\\n",
    "                                .add(df_OD['PROMOTION_REBATE_AMT'], fill_value=0) \\\n",
    "                                .add(df_OD['SPECIAL_GP_AMT'], fill_value=0) \\\n",
    "                                .add(df_OD['DISCOUNT_SHARING_AMT'], fill_value=0)\n",
    "\n",
    "df_OD['TOTAL_Supplier_Funding'] = df_OD['PROMOTION_REBATE_AMT'] \\\n",
    "                                    .add(df_OD['SPECIAL_GP_AMT'], fill_value=0) \\\n",
    "                                    .add(df_OD['DISCOUNT_SHARING_AMT'], fill_value=0)\n",
    "\n",
    "df_OD['upd_total_disc'] = (df_OD['base_price'] - df_OD['price']) * df_OD['units']\n",
    "df_OD['upd_GROSS_SALES'] = df_OD['base_price'] * df_OD['units']\n",
    "\n",
    "assert df_OD.shape[0]==original_df_OD_count, \"[ERROR] Rows count has changed\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94a49889",
   "metadata": {},
   "source": [
    "# <span style=\"color:#c6aa3d\">3. Calculating RMI</span><a class=\"anchor\" id=\"3-bullet\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f1d58d5",
   "metadata": {},
   "source": [
    "### 3.1 Computing RMI for relevant timeframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "18685441",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_RMI = df_OD.copy()\n",
    "\n",
    "# Filtering for specified timeframe\n",
    "df_RMI = df_RMI[(df_RMI['ds'] >= config.OD_ds_start) & (df_RMI['ds'] <= config.OD_ds_end)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5664071b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_RMI['baseline_sales'] = df_RMI['base_price'] * df_RMI['yhat_baseline']\n",
    "df_RMI['baseline_cost'] = (df_RMI['TOTAL_PRODUCT_COST'] / df_RMI['units']) * df_RMI['yhat_baseline']\n",
    "df_RMI['baseline_margin'] = df_RMI['baseline_sales'] - df_RMI['baseline_cost']\n",
    "\n",
    "df_RMI['actual_margin'] = df_RMI['NET_SALES_AMT_INC_VAT'] - df_RMI['COST_OF_GOODS_SOLD']\n",
    "\n",
    "df_RMI['margin_uplift'] = df_RMI['actual_margin'] - df_RMI['baseline_margin']\n",
    "\n",
    "df_RMI = df_RMI.groupby(group_OD_depth).agg({'margin_uplift':'sum',\n",
    "                                            'baseline_sales':'sum'}).reset_index()\n",
    "\n",
    "df_RMI['RMI'] = df_RMI['margin_uplift']/df_RMI['baseline_sales']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d088713",
   "metadata": {},
   "source": [
    "### 3.2 Exporting results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "df68a713",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_RMI.to_csv(notebook_output_path + 'rmi_aggregated.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "086eda31",
   "metadata": {},
   "source": [
    "# <span style=\"color:#c6aa3d\">4. Optimal discount scenario planner input preparation</span><a class=\"anchor\" id=\"4-bullet\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b82bb8d",
   "metadata": {},
   "source": [
    "### 4.1 Merging SKU parameter/coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "44685357",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_select_params_df_final = param_df_final[['rfg','discount',\n",
    "                               'DISCOUNT_RULE_Line Discount', 'DISCOUNT_RULE_Mix&Match Amount',\n",
    "                               'DISCOUNT_RULE_Mix&Match Quantity']]\n",
    "df_select_params_df_final = df_select_params_df_final.add_prefix('coeff_').rename(columns={'coeff_rfg':'rfg'})\n",
    "\n",
    "original_df_OD_count = df_OD.shape[0]\n",
    "\n",
    "df_OD = df_OD.merge(df_select_params_df_final, on='rfg', how='inner')\n",
    "\n",
    "df_OD['NS'] = df_OD['NET_SALES_AMT_INC_VAT']\n",
    "\n",
    "assert df_OD.shape[0]==original_df_OD_count, \"[ERROR] Rows count has changed\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e67bed2a",
   "metadata": {},
   "source": [
    "### 4.2 Calculate weighted discount and mechanic coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e73f478a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_params_OD_coeff = df_OD.groupby(group_OD_depth+['sku_id_upd']).agg({\n",
    "                                                    'coeff_discount':'mean',\n",
    "                                                    'coeff_DISCOUNT_RULE_Line Discount':'mean',\n",
    "                                                    'coeff_DISCOUNT_RULE_Mix&Match Amount':'mean',\n",
    "                                                    'coeff_DISCOUNT_RULE_Mix&Match Quantity':'mean',    \n",
    "                                                    'NS':'sum'}).reset_index()\n",
    "\n",
    "for var in ['coeff_'+i for i in ['discount','DISCOUNT_RULE_Line Discount','DISCOUNT_RULE_Mix&Match Amount', 'DISCOUNT_RULE_Mix&Match Quantity']]:\n",
    "    df_params_OD_coeff[var+'_times_NS'] = df_params_OD_coeff[var]* df_params_OD_coeff['NS']\n",
    "\n",
    "df_params_OD_coeff = df_params_OD_coeff.groupby(group_OD_depth).agg({\n",
    "                                                    'sku_id_upd':'count',\n",
    "                                                    'coeff_discount_times_NS':'sum',\n",
    "                                                    'coeff_DISCOUNT_RULE_Line Discount_times_NS':'sum',\n",
    "                                                    'coeff_DISCOUNT_RULE_Mix&Match Amount_times_NS':'sum',\n",
    "                                                    'coeff_DISCOUNT_RULE_Mix&Match Quantity_times_NS':'sum',\n",
    "                                                    'NS':'sum'}).reset_index()\n",
    "\n",
    "df_params_OD_coeff = df_params_OD_coeff.rename(columns={'sku_id_upd':'elasticity_sku_count'})\n",
    "\n",
    "for var in ['coeff_'+i for i in ['discount','DISCOUNT_RULE_Line Discount','DISCOUNT_RULE_Mix&Match Amount', 'DISCOUNT_RULE_Mix&Match Quantity']]:\n",
    "    df_params_OD_coeff[var+'_wtd_NS'] = df_params_OD_coeff[var+'_times_NS']/df_params_OD_coeff['NS']\n",
    "\n",
    "df_params_OD_coeff = df_params_OD_coeff.loc[:,~(df_params_OD_coeff.columns.str.endswith('_times_NS'))]\n",
    "df_params_OD_coeff = df_params_OD_coeff.drop(columns=['NS'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb9b7ff8",
   "metadata": {},
   "source": [
    "### 4.3 Preparing Optimal discount scenario planner input for relevant timeframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9b9bdc20",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_SP_OD = df_OD.copy()\n",
    "\n",
    "# Filtering for timeframe\n",
    "df_SP_OD = df_SP_OD[(df_SP_OD['ds'] >= config.OD_ds_start) & (df_SP_OD['ds'] <= config.OD_ds_end)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "289484f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_SP_OD = df_SP_OD.groupby(group_OD_depth).agg({\n",
    "                                        'sku_id_upd':'nunique',\n",
    "                                        'TOTAL_Supplier_Funding':'sum',\n",
    "                                        'TOTAL_PRODUCT_COST':'sum',\n",
    "                                        'upd_GROSS_SALES':'sum',\n",
    "                                        'upd_total_disc':'sum',\n",
    "                                        'units':'sum',\n",
    "                                        'yhat_baseline':'sum'}).reset_index()\n",
    "\n",
    "df_SP_OD = df_SP_OD.rename(columns={'sku_id_upd':'modeled_sku_count'})\n",
    "\n",
    "df_SP_OD['TPC_perunit'] = np.where(df_SP_OD['units']==0, 0, df_SP_OD['TOTAL_PRODUCT_COST']/df_SP_OD['units'])\n",
    "df_SP_OD['base_price'] = np.where(df_SP_OD['units']==0, 0, df_SP_OD['upd_GROSS_SALES']/df_SP_OD['units'])\n",
    "df_SP_OD['perc_supplier_funding'] = np.where(df_SP_OD['upd_total_disc']==0,0, df_SP_OD['TOTAL_Supplier_Funding']/df_SP_OD['upd_total_disc'])\n",
    "df_SP_OD['perc_current_discount'] = df_SP_OD['upd_total_disc']/df_SP_OD['upd_GROSS_SALES']\n",
    "\n",
    "# Creating excluding vat version of base price and % supplier funding\n",
    "# Since we did base price flattening in baseline notebook, we can't calculate base price exc vat directly from GROSS_SALES_EXC_VAT\n",
    "df_SP_OD['base_price'] = df_SP_OD['base_price']/(1 + config.VAT_perc)\n",
    "\n",
    "# Supplier funding is represented as a proportion of discount\n",
    "# Since discount is now including VAT, the denominator in perc_supplier_funding equation gets divided by (1+vat),\n",
    "# effectively implying that %supplier funding gets multiplied by (1+vat)\n",
    "df_SP_OD['perc_supplier_funding'] = df_SP_OD['perc_supplier_funding']*(1 + config.VAT_perc)\n",
    "\n",
    "# Merge coefficients\n",
    "df_SP_OD = df_SP_OD.merge(df_params_OD_coeff, on=group_OD_depth, how='inner')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da8fac1e",
   "metadata": {},
   "source": [
    "### 4.4 Calculating net sales and profit coverage for extrapolation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "11b87462",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_OD_coverage = full_df_grouped.copy()\n",
    "df_OD_coverage = df_OD_coverage.merge(df_sku_new_mapping, on='sku_id_upd', how='inner')\n",
    "\n",
    "# Filtering for timeframe\n",
    "df_OD_coverage = df_OD_coverage[(df_OD_coverage['ds']>=config.OD_ds_start) & (df_OD_coverage['ds']<=config.OD_ds_end)]\n",
    "\n",
    "df_OD_coverage['Profit_exc_VAT'] = df_OD_coverage['NET_SALES_AMT_EXC_VAT'] - df_OD_coverage['COST_OF_GOODS_SOLD']\n",
    "\n",
    "df_OD_coverage = df_OD_coverage.groupby(group_OD_depth).agg({'Profit_exc_VAT':'sum',\n",
    "                                                            'NET_SALES_AMT_EXC_VAT':'sum'}).reset_index()\n",
    "\n",
    "df_OD_coverage = df_OD_coverage.rename(columns={'Profit_exc_VAT':'Total_Profit_exc_VAT',\n",
    "                                               'NET_SALES_AMT_EXC_VAT':'Total_NET_SALES_AMT_EXC_VAT'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "572a3778",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_model_coverage = df_OD.copy()\n",
    "\n",
    "# Filtering for timeframe\n",
    "df_model_coverage = df_model_coverage[(df_model_coverage['ds']>=config.OD_ds_start) & (df_model_coverage['ds']<=config.OD_ds_end)]\n",
    "\n",
    "df_model_coverage['Profit_exc_VAT'] = df_model_coverage['NET_SALES_AMT_EXC_VAT'] - df_model_coverage['COST_OF_GOODS_SOLD']\n",
    "\n",
    "df_model_coverage = df_model_coverage.groupby(group_OD_depth).agg({'Profit_exc_VAT':'sum',\n",
    "                                                            'NET_SALES_AMT_EXC_VAT':'sum'}).reset_index()\n",
    "\n",
    "df_model_coverage = df_model_coverage.merge(df_OD_coverage, on=group_OD_depth, how='left')\n",
    "\n",
    "df_model_coverage['Profit_Coverage_exc_VAT'] = df_model_coverage['Profit_exc_VAT']/df_model_coverage['Total_Profit_exc_VAT']\n",
    "df_model_coverage['Net_Sales_Coverage_exc_VAT'] = df_model_coverage['NET_SALES_AMT_EXC_VAT']/df_model_coverage['Total_NET_SALES_AMT_EXC_VAT']\n",
    "\n",
    "df_model_coverage = df_model_coverage[group_OD_depth+ ['Profit_exc_VAT','NET_SALES_AMT_EXC_VAT',\n",
    "                                                'Total_Profit_exc_VAT','Total_NET_SALES_AMT_EXC_VAT',\n",
    "                                                'Profit_Coverage_exc_VAT','Net_Sales_Coverage_exc_VAT']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6907a4bd",
   "metadata": {},
   "source": [
    "### 4.5 Merging profit and sales coverage to main input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0b4ce8fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "original_SP_OD_rows = df_SP_OD.shape[0]\n",
    "\n",
    "df_SP_OD = df_SP_OD.merge(df_model_coverage, on=group_OD_depth, how='inner')\n",
    "\n",
    "assert original_SP_OD_rows == df_SP_OD.shape[0], \"[ERROR] Rows count has changed\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bc01876",
   "metadata": {},
   "source": [
    "### 4.6 Exporting optimal discount scenario output for populating scenario planner excel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5ff338c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a concatenated indicator for grouping fields\n",
    "df_SP_OD['group_OD_depth'] = ''\n",
    "for element in group_OD_depth:\n",
    "    if element!='CREDIT_CONSIGN':\n",
    "        df_SP_OD['group_OD_depth'] = df_SP_OD['group_OD_depth'] +'_'+ df_SP_OD[element]\n",
    "\n",
    "df_SP_OD['group_OD_depth'] = df_SP_OD['group_OD_depth'].str.strip('_')\n",
    "\n",
    "# Reordering columns- Moving group indicator to the beginning\n",
    "group_OD_depth_column = df_SP_OD.pop('group_OD_depth')\n",
    "df_SP_OD.insert(0, 'group_OD_depth', group_OD_depth_column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "24e0e8d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_SP_OD.to_csv(notebook_output_path + 'optimal_discount_scenario_input.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07b2fa0d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a5d2b326fdc3f4118f37633ddd42160fa8b53277d5703fd7f711e9abf10d95be"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
